{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932f990b-e6be-42ac-8a9e-bf4421460edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nico/panoseti/panoseti-software/cloud-detection/model_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e19fb572-1574-457f-abe0-409b77ce676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from time import sleep\n",
    "import math\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.facecolor\"] = 'grey'\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "import tqdm.notebook as tqdm\n",
    "import gc\n",
    "\n",
    "sys.path.append('../dataset_construction')\n",
    "sys.path.append('../../util')\n",
    "from pano_utils import *\n",
    "from panoseti_file_interfaces import ObservingRunInterface\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "\n",
    "from cnn_model import *\n",
    "from data_loaders import *\n",
    "from training_utils import *\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2e0daee-694f-431e-af67-4b90459cac8e",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Frame browsing utils\n",
    "# cloudy = labeled[labeled['label'] == 'not_clear_cloudy']\n",
    "# clear = labeled[labeled['label'] == 'clear_night_sky']\n",
    "img_type = 'raw-derivative.-60'\n",
    "# img_type = 'raw-original'\n",
    "# img_type = 'raw-fft'\n",
    "\n",
    "def make_img_grid(label, cols=8, rows_per_plot=6):\n",
    "    \"\"\"Grid of all classified images labeled as the given label\"\"\"\n",
    "    with_label = labeled.loc[labeled['label'] == label]\n",
    "    imgs = []\n",
    "\n",
    "    for fuid in with_label['feature_uid']:\n",
    "        data = np.load(get_path(fuid, img_type), allow_pickle=False)\n",
    "        imgs.append(data)\n",
    "    if len(imgs) == 0:\n",
    "        print(f'No images labeled as \"{label}\"')\n",
    "        return\n",
    "    else:\n",
    "        print(f'Images you classified as \"{label}\":')\n",
    "    # Limit num rows in plot to ensure consistently-sized figures\n",
    "    rows = math.ceil(len(imgs) / cols)\n",
    "    num_subplots = rows_per_plot * cols\n",
    "    for plot_idx in range(math.ceil(rows / rows_per_plot)):\n",
    "        fig = plt.figure(figsize=(3. * rows_per_plot, 3. * cols))\n",
    "        grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                         nrows_ncols=(rows_per_plot, cols),  # creates width x height grid of axes\n",
    "                         axes_pad=0.3,  # pad between axes in inch.\n",
    "                         )\n",
    "        for i in range(num_subplots):\n",
    "            img_idx = plot_idx * num_subplots + i\n",
    "            if img_idx < len(imgs):\n",
    "                ax = grid[i]\n",
    "                img = imgs[img_idx]\n",
    "                feature_uid = with_label['feature_uid'].iloc[img_idx]\n",
    "                ax.set_title(f'{23}{feature_uid[:6]}')  # Label each plot with first 6 chars of feature_uid\n",
    "                ax.imshow(img, vmin=-150, vmax=150, cmap='icefire')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "def add_module_id_and_time(df):\n",
    "    df_with_pano_uid = pd.merge(\n",
    "        left = df,\n",
    "        right = inference_data.inference_session.feature_df,\n",
    "        on = 'feature_uid'\n",
    "    )\n",
    "    df_with_module_id_and_time = pd.merge(\n",
    "        left = df_with_pano_uid,\n",
    "        right = inference_data.inference_session.pano_df,\n",
    "        on = 'pano_uid'\n",
    "    ).loc[:,['feature_uid', 'module_id', 'label', 'frame_unix_t']]\n",
    "    df_with_module_id_and_time['date'] = pd.to_datetime(df_with_module_id_and_time['frame_unix_t'], unit='s')\n",
    "    return df_with_module_id_and_time\n",
    "\n",
    "def get_with_label(label, module_id):\n",
    "    if label == 'cloudy':\n",
    "        with_label = cloudy\n",
    "    elif label == 'clear':\n",
    "        with_label = clear\n",
    "    else:\n",
    "        raise ValueError('label must be either \"cloudy\" or \"clear\"')\n",
    "    if module_id != 'All':\n",
    "        assert 'module_id' in with_label, \"'module_id' must be added to the data frame.\"\n",
    "        assert module_id in with_label['module_id'].unique(), f\"Found no data with module_id = {module_id}.\"\n",
    "        with_label = with_label[with_label['module_id'] == module_id]\n",
    "    return with_label\n",
    "\n",
    "\n",
    "def do_movie(label, step, start_frame=1, frame_time=0.01, module_id=None):\n",
    "    try:\n",
    "        # for i, fuid in enumerate(with_label['feature_uid'][::step]):\n",
    "        with_label = get_with_label(label, module_id)\n",
    "\n",
    "        for i in range(max(min(start_frame, len(with_label)), 1), len(with_label) + 1, step):\n",
    "            plot_frame(module_id, label, step, i)\n",
    "            display.clear_output(wait=True)\n",
    "            # plt.show()\n",
    "            sleep(frame_time)\n",
    "            # plt.close()\n",
    "        print('Done')\n",
    "    except KeyboardInterrupt:\n",
    "        print('Exiting...')\n",
    "        return\n",
    "    finally:\n",
    "        plt.close()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "def browse_labels(continuous_update=True):\n",
    "    try:\n",
    "        initial_label = 'cloudy'\n",
    "        label_options = ['cloudy', 'clear']\n",
    "        if len(cloudy) == 0 and len(clear) == 0:\n",
    "            raise ValueError('No images!')\n",
    "        elif len(cloudy) == 0:\n",
    "            initial_label = 'clear'\n",
    "            label_options.remove('cloudy')\n",
    "        initial_df = get_with_label(initial_label, module_id='All')\n",
    "\n",
    "        module_id_options = ['All']\n",
    "        module_id_options.extend(list(labeled['module_id'].unique()))\n",
    "        # print(module_id_options)\n",
    "        \n",
    "        i_widget = widgets.IntSlider(\n",
    "            min=1,\n",
    "            max=len(initial_df),\n",
    "            step=1,\n",
    "            value=1, \n",
    "            description='seqno',\n",
    "            continuous_update=continuous_update,\n",
    "            layout=Layout(width='85%'),\n",
    "            auto_advance=True)\n",
    "        label_widget = widgets.Dropdown(\n",
    "            options=label_options,\n",
    "            value = initial_label,\n",
    "            description='label',\n",
    "            layout=Layout(width='50%', justify_content='center')\n",
    "        )\n",
    "        module_id_widget = widgets.Dropdown(\n",
    "            options=module_id_options,\n",
    "            value = 'All',\n",
    "            description='module_id',\n",
    "            layout=Layout(width='50%', justify_content='center')\n",
    "        )\n",
    "\n",
    "        def update_i_widget(*args):\n",
    "            label = label_widget.value\n",
    "            module_id = module_id_widget.value\n",
    "            with_label = get_with_label(label, module_id)\n",
    "            i_widget.max = len(with_label)\n",
    "            i_widget.value = min(i_widget.value, len(with_label))\n",
    "                \n",
    "        label_widget.observe(update_i_widget, 'value')\n",
    "        module_id_widget.observe(update_i_widget, 'value')\n",
    "        interact(\n",
    "            plot_frame,\n",
    "            label = label_widget,\n",
    "            step = fixed(1),\n",
    "            i = i_widget,\n",
    "            module_id = module_id_widget\n",
    "        )\n",
    "    except KeyboardInterrupt:\n",
    "        print('Exiting...')\n",
    "        return\n",
    "    finally:\n",
    "        plt.close()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "def plot_frame(module_id, label, step, i):\n",
    "    with_label = get_with_label(label, module_id)\n",
    "    fuid, actual_module_id, date = with_label[['feature_uid', 'module_id', 'date']].iloc[i - 1]\n",
    "    data = np.load(get_path(fuid, img_type))    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10.5, 4.8), constrained_layout=True)\n",
    "    # fig.suptitle(f'[{label}] feature_uid: {fuid[:9]:>10}; ({(i-1)//step + 1} / {len(with_label) // step})')\n",
    "    fig.suptitle(f'[inference: \"{label}\"] '\n",
    "                 f'[module: {actual_module_id}] '\n",
    "                 f'[fuid: {fuid[:9]}] '\n",
    "                 f'[seqno: {i} / {len(with_label)}]\\n'\n",
    "                 f'[UTC: {date}]')\n",
    "\n",
    "    # FFT of original stacked original\n",
    "    fft_idx = 0\n",
    "    shape = (64, 64)\n",
    "    data = np.load(get_path(fuid, 'raw-derivative.-60'))\n",
    "    window_type = \"hann\"\n",
    "    data = data * window(window_type, data.shape)\n",
    "    # data[data < 0] = 1\n",
    "    data = np.abs(fftn(data, shape))\n",
    "    data = fftshift(data)\n",
    "    data = np.log(data)\n",
    "    im_fft = axs[fft_idx].imshow(\n",
    "        data, vmin=3.5, vmax=12, cmap='mako'\n",
    "    )\n",
    "    cbar_fft = fig.colorbar(im_fft, label='$\\log|X[k, \\ell]|$', fraction=0.046, location='bottom')\n",
    "    axs[fft_idx].axis('off')\n",
    "    axs[fft_idx].set_title('FFT of Derivative')\n",
    "\n",
    "    # Original stacked pano image\n",
    "    orig_idx = 2\n",
    "    im_orig = axs[orig_idx].imshow(\n",
    "        np.load(get_path(fuid, 'raw-original')), vmin=30, vmax=275 * 70, cmap='rocket'#cmap='crest_r'\n",
    "    )\n",
    "    cbar_orig = fig.colorbar(im_orig, label='Counts', fraction=0.046, location='bottom')\n",
    "    axs[orig_idx].axis('off')\n",
    "    axs[orig_idx].set_title('Original [6ms integr.]')\n",
    "\n",
    "    # -60 second time derivative\n",
    "    deriv_idx = 1\n",
    "    im_deriv = axs[deriv_idx].imshow(\n",
    "        np.load(get_path(fuid, 'raw-derivative.-60')), vmin=-125*50, vmax=125*50, cmap='icefire'\n",
    "    )\n",
    "    cbar_deriv = fig.colorbar(im_deriv, label = r'$\\Delta$ Counts', fraction=0.046, location='bottom')\n",
    "    axs[deriv_idx].axis('off')\n",
    "    axs[deriv_idx].set_title('Derivative: Orig(0s) – Orig(-60s)')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a0a8910-687c-45bf-a3bd-963ee1b04417",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "batch_id = 1011   # Cloudy data, not in training set\n",
    "# batch_id = 9   # Clear data, not in training set\n",
    "\n",
    "# transform = v2.Compose([\n",
    "#     v2.ToTensor(),\n",
    "#     # v2.RandomHorizontalFlip(),\n",
    "#     # v2.RandomVerticalFlip(),\n",
    "#     v2.Normalize(mean=[0], std=[67]),\n",
    "#     v2.ToDtype(torch.float, scale=True),\n",
    "#     # v2.ColorJitter(0.5, None, None, None),\n",
    "#     # v2.GaussianBlur(kernel_size=(5, 5), sigma=(0.2, 0.5))\n",
    "# ])\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=[0], std=[1000]),\n",
    "    v2.ToDtype(torch.float),\n",
    "    # v2.ColorJitter(0.5, None, None, None),\n",
    "    # v2.GaussianBlur(kernel_size=(5, 5), sigma=(0.2, 0.5))\n",
    "])\n",
    "\n",
    "# transform = v2.Compose([\n",
    "#     v2.ToTensor(),\n",
    "#     # v2.Normalize(mean=[0], std=[67]),\n",
    "#     v2.ToDtype(torch.float, scale=True)\n",
    "# ])\n",
    "\n",
    "inference_data = CloudDetectionInference(\n",
    "    batch_id = batch_id,\n",
    "    transform = transform\n",
    ")\n",
    "get_path = inference_data.inference_session.get_pano_feature_fpath\n",
    "inference_loader = torch.utils.data.DataLoader(\n",
    "  dataset=inference_data,\n",
    "  batch_size=batch_size\n",
    ")\n",
    "# img_type = 'raw-derivative.-60'\n",
    "# img_type = 'raw-original'\n",
    "# img_type = 'raw-fft'\n",
    "\n",
    "# images = [inference_data[i][img_type] for i in np.random.choice(len(inference_data), size=min(30, len(inference_data)), replace=False)]\n",
    "# plt.imshow(torchvision.utils.make_grid(torch.stack(images), nrow=10, padding=5).numpy().transpose((1, 2, 0)))\n",
    "# print(inference_data)\n",
    "\n",
    "# with open('../model_training/model_summary.txt', 'r') as f:\n",
    "#     print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58fb98ca-744e-4275-a624-449c01195445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961e913a585046d6b35e64d8208b0fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset_construction/inference_batch_labels/task_cloud-detection.type_inference.batch-id_1011.user-uid_INFERENCE\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "model = CloudDetection()\n",
    "model.load_state_dict(torch.load('../model_training/best_cloud_detection_model.pth'))\n",
    "# model.load_state_dict(torch.load('../model_training/best_cloud_detection_model_2-26-24.pth'))\n",
    "# model.load_state_dict(torch.load('../model_training/best_cloud_detection_model_2-24-24.pth'))\n",
    "device = get_device()\n",
    "model.to(device);\n",
    "\n",
    "\n",
    "predictions = np.array([], dtype=int)\n",
    "with torch.no_grad():\n",
    "    model.eval() # Put model in eval mode\n",
    "    for img_data in tqdm.tqdm(inference_loader, unit=\"batch\"):\n",
    "        x = img_data\n",
    "        x = x.to(device=device, dtype=torch.float)\n",
    "        pred = model(x)\n",
    "        predictions = np.concatenate((predictions, torch.argmax(pred, dim=1).to('cpu').numpy()))\n",
    "inference_data.inference_session.add_labels(predictions)\n",
    "inference_data.inference_session.write_labels(save_to_training_data=False)\n",
    "del model\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fa66cfa-6ec2-4f40-b4e1-1db33796f7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncloudy = 1114, nclear = 2\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "labeled = add_module_id_and_time(inference_data.inference_session.labeled_df)\n",
    "\n",
    "cloudy = labeled[labeled['label'] == 'not_clear_cloudy']\n",
    "clear = labeled[labeled['label'] == 'clear_night_sky']\n",
    "print(f'ncloudy = {len(cloudy)}, nclear = {len(clear)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "726969aa-9ca6-423b-9ec7-38b549a3e3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9eb68900a0b43e294ae602775fd3d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='module_id', layout=Layout(justify_content='center', width='50%'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "browse_labels(continuous_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fd1b931-1d51-4def-8567-e7fe8f4a962b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "# View all cloudy images\n",
    "# label can be set to either 'cloudy' or 'clear'\n",
    "gc.collect()\n",
    "do_movie(label = 'cloudy', step=1, start_frame=250, module_id=1, frame_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902577ab-190c-41d9-8504-433816c43108",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_img_grid('not_clear_cloudy')\n",
    "make_img_grid('clear_night_sky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a41b2-493e-4b9c-946c-84151363e033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
